{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Step 1: Read in data from file. My data was in csv format, and I used pandas to house the data in a dataframe. I also shuffle the samples in the data and extract the names of the targets (drug names) I will use in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseNumber</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Age</th>\n",
       "      <th>Residence City</th>\n",
       "      <th>Residence State</th>\n",
       "      <th>Residence County</th>\n",
       "      <th>Death City</th>\n",
       "      <th>Death State</th>\n",
       "      <th>...</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Tramad</th>\n",
       "      <th>Morphine (not heroin)</th>\n",
       "      <th>Other</th>\n",
       "      <th>Any Opioid</th>\n",
       "      <th>MannerofDeath</th>\n",
       "      <th>AmendedMannerofDeath</th>\n",
       "      <th>DeathLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17-785</td>\n",
       "      <td>10/04/2017</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Windham</td>\n",
       "      <td>CT</td>\n",
       "      <td>Windham</td>\n",
       "      <td>Windham</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windham, CT\\n(41.699744, -72.157703)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17-749</td>\n",
       "      <td>09/15/2017</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Middlebury</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waterbury, CT\\n(41.554261, -73.043069)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-2915</td>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>48.0</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRIDGEPORT, CT\\n(41.179195, -73.189476)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-2334</td>\n",
       "      <td>02/07/2016</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NORWICH</td>\n",
       "      <td>CT</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW LONDON, CT\\n(41.355167, -72.099561)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17-206</td>\n",
       "      <td>03/09/2017</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>52.0</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CTCCTTCT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Combined Effects of Sertraline, Hydroxyzine, F...</td>\n",
       "      <td>Hartford, CT\\n(41.765775, -72.673356)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseNumber</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Age</th>\n",
       "      <th>Residence City</th>\n",
       "      <th>Residence State</th>\n",
       "      <th>Residence County</th>\n",
       "      <th>Death City</th>\n",
       "      <th>Death State</th>\n",
       "      <th>...</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Tramad</th>\n",
       "      <th>Morphine (not heroin)</th>\n",
       "      <th>Other</th>\n",
       "      <th>Any Opioid</th>\n",
       "      <th>MannerofDeath</th>\n",
       "      <th>AmendedMannerofDeath</th>\n",
       "      <th>DeathLoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17-785</td>\n",
       "      <td>10/04/2017</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Windham</td>\n",
       "      <td>CT</td>\n",
       "      <td>Windham</td>\n",
       "      <td>Windham</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windham, CT\\n(41.699744, -72.157703)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17-749</td>\n",
       "      <td>09/15/2017</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Middlebury</td>\n",
       "      <td>CT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waterbury, CT\\n(41.554261, -73.043069)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-2915</td>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>48.0</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIRFIELD</td>\n",
       "      <td>BRIDGEPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRIDGEPORT, CT\\n(41.179195, -73.189476)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-2334</td>\n",
       "      <td>02/07/2016</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NORWICH</td>\n",
       "      <td>CT</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>NEW LONDON</td>\n",
       "      <td>CT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW LONDON, CT\\n(41.355167, -72.099561)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17-206</td>\n",
       "      <td>03/09/2017</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>52.0</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CT</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>HARTFORD</td>\n",
       "      <td>CTCCTTCT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Accident</td>\n",
       "      <td>Combined Effects of Sertraline, Hydroxyzine, F...</td>\n",
       "      <td>Hartford, CT\\n(41.765775, -72.673356)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataframe = pd.read_csv(\"Accidental_Drug_Related_Deaths__2012-2017.csv\")\n",
    "\n",
    "drug_names = dataframe.columns[15:27]\n",
    "\n",
    "# shuffle data\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Select features from dataset to train/test on. For some of my categorical data, a sample could belong to multiple categories for a feature. Thus, I did the extra step of separating each category for a sample's feature into a list of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(features, dataframe):\n",
    "    \"\"\"\n",
    "    Extracts selected features from data\n",
    "    :param features: list of column names \n",
    "    :param dataframe: the dataframe to select features from\n",
    "    :return: map of selected features to numpy arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_frame = {}\n",
    "    \n",
    "    # add features to feature_frame\n",
    "    for feature in features:\n",
    "        try:\n",
    "            # convert values to numpy array\n",
    "            feature_frame[feature] = np.array(dataframe[feature])\n",
    "        except:\n",
    "            print(\"feature not in dataframe\")\n",
    "            raise\n",
    "        \n",
    "    return feature_frame\n",
    "\n",
    "# sanitize data -- drop records with NA in feature columns\n",
    "dataframe.dropna(subset=[\"Sex\",\"Race\",\"Age\"],inplace=True)\n",
    "\n",
    "features = select_features([\"Sex\",\"Race\",\"Age\"],dataframe)\n",
    "\n",
    "def process_categorical_data(feature,delimiter=None):\n",
    "    \"\"\"\n",
    "    convert categorical data to usable format\n",
    "    :param feature: panda series to be processed\n",
    "    :param delimiter: to separate multiple values for a sample's feature \n",
    "    :return: tensor with modified values\n",
    "    \"\"\"\n",
    "    \n",
    "    # create new tensors\n",
    "    values = []\n",
    "    for value in feature:\n",
    "        # in case number present\n",
    "        try:\n",
    "            new_value = value.split(delimiter)\n",
    "            values.append(new_value)\n",
    "        except:\n",
    "            values.append([value])\n",
    "        \n",
    "    return values\n",
    "\n",
    "# special treatment for categorical variables-- convert each race attribute for a sample into a list item\n",
    "features[\"Race\"] = process_categorical_data(features[\"Race\"],delimiter=\", \")\n",
    "\n",
    "# special treatment for categorical variables-- convert each gender attribute for a sample into a list item\n",
    "features[\"Sex\"] = process_categorical_data(features[\"Sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Convert data to numerical form. Since I had categorical data, I encoded them using one-hot encoding. I also saved the encoding scheme for converting my results back to their respective categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature(feature):\n",
    "    \"\"\"\n",
    "    Convert categorical data to numerical array using multihot-encoding\n",
    "    :param feature: list of categories\n",
    "    :return: numpy array of data, encoding scheme\n",
    "    \"\"\"\n",
    "    \n",
    "    samples = len(feature)\n",
    "   \n",
    "    # index of 1's for each sample encoding\n",
    "    data_indices = []\n",
    "    \n",
    "    # encode each sample\n",
    "    vocab = {}\n",
    "    index = 0\n",
    "    for sample in feature:\n",
    "        sample_indices = []\n",
    "        for category in sample:\n",
    "            if category not in vocab: \n",
    "                vocab[category] = index\n",
    "                index+=1\n",
    "            sample_indices.append(vocab[category])\n",
    "        data_indices.append(sample_indices)\n",
    "        \n",
    "    # create tensor and load in 1's\n",
    "    num_data = np.zeros((samples,index),dtype=np.float32)\n",
    "    row = 0\n",
    "    for sample_indices in data_indices:\n",
    "        for index in sample_indices:\n",
    "            num_data[row,index] = 1\n",
    "        row+=1\n",
    "        \n",
    "    return num_data, vocab\n",
    "\n",
    "# encode race and gender\n",
    "encoded_race, race_vocab = encode_feature(features[\"Race\"])\n",
    "encoded_gender, gender_vocab = encode_feature(features[\"Sex\"])\n",
    "\n",
    "# concatenate feature tensors into one big dataset\n",
    "data = reduce(lambda x,y: np.column_stack((x,y)),[encoded_gender,features[\"Age\"],encoded_race]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Select targets from data to train/test on. Here I use the drug names I extracted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Cocaine</th>\n",
       "      <th>Fentanyl</th>\n",
       "      <th>Oxycodone</th>\n",
       "      <th>Oxymorphone</th>\n",
       "      <th>EtOH</th>\n",
       "      <th>Hydrocodone</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Tramad</th>\n",
       "      <th>Morphine (not heroin)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Cocaine</th>\n",
       "      <th>Fentanyl</th>\n",
       "      <th>Oxycodone</th>\n",
       "      <th>Oxymorphone</th>\n",
       "      <th>EtOH</th>\n",
       "      <th>Hydrocodone</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Tramad</th>\n",
       "      <th>Morphine (not heroin)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_labels(targets,dataframe):\n",
    "    \"\"\"\n",
    "    Extracts selected labels from data\n",
    "    :param targets: list of target data\n",
    "    :param dataframe: the dataframe to select targets from\n",
    "    :return: dataframe of target data\n",
    "    \"\"\"\n",
    "    \n",
    "    target_frame = pd.DataFrame()\n",
    "    \n",
    "    # add targets to target_frame\n",
    "    for target in targets:\n",
    "        try:\n",
    "            target_frame[target] = dataframe[target]\n",
    "        except:\n",
    "            print(\"feature not in dataframe\")\n",
    "            raise\n",
    "        \n",
    "    return target_frame\n",
    "\n",
    "labels = select_labels(drug_names,dataframe)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Convert target data to numerical form. Since people could die from multiple drugs, I used multihot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 0., 0.],\n       [1., 0., 1., ..., 0., 0., 0.],\n       [1., 1., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 1., ..., 0., 0., 0.],\n       [1., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multihot_binarycolumns(labels,new_column_name,binary_values = defaultdict(int)):\n",
    "    \"\"\"\n",
    "    Multihot encoding of multiple columns with binary values\n",
    "    :param labels: dataframe to be encoded\n",
    "    :param binary_values: dictionary mapping dataset binary values to a 1 or 0\n",
    "    :param new_column_name: name of encoded column\n",
    "    :return: series object\n",
    "    \"\"\"\n",
    "    \n",
    "    # create encoded column\n",
    "    data = np.zeros((labels.shape),dtype=np.float32)\n",
    "    \n",
    "    # convert binary values to 1's and 0's for each item    \n",
    "    for index, row in labels.iterrows():\n",
    "        # weird bug where index can be equal to num rows\n",
    "        if index >= labels.shape[0]:\n",
    "            break\n",
    "        data[index] = row.apply(lambda death: binary_values[death])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# convert 'Y' to 1 and otherwise to 0\n",
    "binary_values = defaultdict(int)\n",
    "binary_values[\"Y\"] = 1\n",
    "\n",
    "death = multihot_binarycolumns(labels,\"death\", binary_values=binary_values)\n",
    "death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Construct pipeline to feed data into model. I used a batch system where I created an iterator to return the next batch of data as needed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(features,targets,batch_size = None,num_epochs = None):\n",
    "    \"\"\"\n",
    "    create batches to be fed into model\n",
    "    :param features: tensor of features\n",
    "    :param targets: tensor of targets\n",
    "    :param batch_size: desired size of batches\n",
    "    :param num_epochs: number of epochs\n",
    "    :return: batch iterator\n",
    "    \"\"\"\n",
    "    \n",
    "    # construct a dataset and configure batching/repeating\n",
    "    ds = Dataset.from_tensor_slices((features,targets)).shuffle(32,reshuffle_each_iteration=True).repeat(count=num_epochs)\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    # retrieve next batch\n",
    "    return ds.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Create the model. In tensorflow, a Graph contains the components of the model (the optimizer, the weights, the loss function, etc.) in the form of \"Tensors\" and \"Operations\". Later on, these objects will be activated in a separate step for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_classifier(training_data, test_data, optimizer_name, learning_rate = 0.1, batch_size=None, epochs=0):\n",
    "    \"\"\"\n",
    "    creates a linear model\n",
    "    :param training_data: numpy array of numerical data\n",
    "    :param test_data: numpy array of numerical targets\n",
    "    :param optimizer: name of optimizer\n",
    "    :param learning_rate: optimizer's learning rate\n",
    "    :param batch_size: size of batches\n",
    "    :param epochs: number of epochs to train\n",
    "    :return: tensorflow graph of net and list of relevant graph variables\n",
    "    \"\"\"\n",
    "    \n",
    "    num_features = training_data.shape[1]\n",
    "    num_labels = test_data.shape[1]\n",
    "    num_samples = training_data.shape[0]\n",
    "    \n",
    "    # construct graph\n",
    "    graph = tf.Graph() \n",
    "    \n",
    "    # construct list of graph vars to run in session -- predictions, loss, optimizer, accuracy\n",
    "    graph_vars = []\n",
    "    \n",
    "    # invoke tensorflow dataflow context\n",
    "    with graph.as_default():\n",
    "        \n",
    "        # split data into train and test tensors following 70/30\n",
    "        train_num = int(training_data.shape[0]*.7)\n",
    "        x_train, y_train = tf.constant(training_data[:train_num,:]), tf.constant(test_data[:train_num,:])\n",
    "        x_test, y_test = tf.constant(training_data[train_num:,:]), tf.constant(test_data[train_num:,:])\n",
    "        \n",
    "        # set up batching\n",
    "        num_batches = int(num_samples/batch_size)\n",
    "        iterator = create_batches(x_train,y_train,batch_size=batch_size,num_epochs=epochs)   \n",
    "        batch_x_train, batch_y_train = iterator.get_next()\n",
    "        \n",
    "        \n",
    "        # set up weights, biases, logits\n",
    "        weights = tf.Variable(tf.truncated_normal([num_features,num_labels]))\n",
    "        biases = tf.Variable(tf.zeros([num_labels]))\n",
    "        logits = tf.add(tf.matmul(batch_x_train,weights), biases)\n",
    "        \n",
    "        # apply softmax to logits and get prediction\n",
    "        train_prediction = tf.nn.softmax(logits, name=\"train_prediction\") \n",
    "        graph_vars.append(train_prediction)\n",
    "        \n",
    "        # cross entropy loss (add 1e-10 constant to avoid log(0))   \n",
    "        loss = -tf.reduce_sum(batch_y_train*tf.log(tf.clip_by_value(train_prediction, 1e-10, 1.0 )),name=\"loss\")\n",
    "        graph_vars.append(loss)\n",
    "        \n",
    "        # optimizer + backpropagation\n",
    "        optimizer = select_optimizer(optimizer_name,learning_rate)\n",
    "        back_propagation = optimizer.minimize(loss)\n",
    "        graph_vars.append(back_propagation)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        equality = tf.equal(tf.argmax(train_prediction,1),tf.argmax(batch_y_train,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(equality,tf.float32),name=\"accuracy\")\n",
    "        graph_vars.append(accuracy)\n",
    "        \n",
    "    return graph, graph_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vanilla_nn(training_data, test_data, optimizer_name, learning_rate = 0.1, batch_size=None, epochs=0, layers = None):\n",
    "    \"\"\"\n",
    "    creates a vanilla (aka fully connected feed forward) neural network\n",
    "    :param training_data: numpy array of numerical data\n",
    "    :param test_data: numpy array of numerical targets\n",
    "    :param optimizer: name of optimizer\n",
    "    :param learning_rate: optimizer's learning rate\n",
    "    :param batch_size: size of batches\n",
    "    :param epochs: number of epochs to train\n",
    "    :param layers: list of tuples for each layer (num hidden nodes, name of activation func). None = linear classifier \n",
    "    :return: tensorflow graph of net and list of relevant graph variables\n",
    "    \"\"\"\n",
    "    \n",
    "    if layers == None:\n",
    "        create_linear_classifier(training_data,test_data,optimizer_name,learning_rate,batch_size,epochs)\n",
    "        return\n",
    "    \n",
    "    num_features = training_data.shape[1]\n",
    "    num_labels = test_data.shape[1]\n",
    "    num_samples = training_data.shape[0]\n",
    "    \n",
    "    # construct graph\n",
    "    graph = tf.Graph() \n",
    "    \n",
    "    # construct list of graph vars to run in session -- predictions, loss, optimizer, accuracy\n",
    "    graph_vars = []\n",
    "    \n",
    "    # invoke tensorflow dataflow context\n",
    "    with graph.as_default():\n",
    "        \n",
    "        # split data into train and test tensors following 70/30\n",
    "        train_num = int(training_data.shape[0]*.7)\n",
    "        x_train, y_train = tf.constant(training_data[:train_num,:]), tf.constant(test_data[:train_num,:])\n",
    "        x_test, y_test = tf.constant(training_data[train_num:,:]), tf.constant(test_data[train_num:,:])\n",
    "        \n",
    "        # set up batching\n",
    "        num_batches = int(num_samples/batch_size)\n",
    "        iterator = create_batches(x_train,y_train,batch_size=batch_size,num_epochs=epochs)   \n",
    "        batch_x_train, batch_y_train = iterator.get_next()\n",
    "        \n",
    "        # tuple of tensor and activation func\n",
    "        hidden_layers = []\n",
    "\n",
    "        prev_rows = num_features \n",
    "        \n",
    "        # create hidden layers\n",
    "        for layer in layers:\n",
    "            \n",
    "            # extract number of nodes in hidden layer and activation func\n",
    "            num_nodes = layer[0]\n",
    "            activation_func = select_activation_func(layer[1])\n",
    "            \n",
    "            # create layer\n",
    "            hidden = tf.Variable(tf.truncated_normal([prev_rows,num_nodes]))\n",
    "            hidden_layers.append((hidden,activation_func))\n",
    "            \n",
    "            # update shape for next layer\n",
    "            prev_rows = num_nodes\n",
    "            \n",
    "        # input to final layer\n",
    "        input_final = forward_pass(batch_x_train,hidden_layers)\n",
    "            \n",
    "        # final layer\n",
    "        final = tf.Variable(tf.truncated_normal([prev_rows,num_labels]))\n",
    "        \n",
    "        # set up biases and logits\n",
    "        biases = tf.Variable(tf.zeros([num_labels]))\n",
    "        logits = tf.add(tf.matmul(input_final,final), biases)\n",
    "        \n",
    "        # apply softmax to logits and get prediction\n",
    "        train_prediction = tf.nn.softmax(logits, name=\"train_prediction\") \n",
    "        graph_vars.append(train_prediction)\n",
    "        \n",
    "        # cross entropy loss (add 1e-10 constant to avoid log(0))   \n",
    "        loss = -tf.reduce_sum(batch_y_train*tf.log(tf.clip_by_value(train_prediction, 1e-10, 1.0 )),name=\"loss\")\n",
    "        graph_vars.append(loss)\n",
    "        \n",
    "        # optimizer + backpropagation\n",
    "        optimizer = select_optimizer(optimizer_name,learning_rate)\n",
    "        back_propagation = optimizer.minimize(loss)\n",
    "        graph_vars.append(back_propagation)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        equality = tf.equal(tf.argmax(train_prediction,1),tf.argmax(batch_y_train,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(equality,tf.float32),name=\"accuracy\")\n",
    "        graph_vars.append(accuracy)\n",
    "        \n",
    "    return graph, graph_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(input, layers):\n",
    "    \"\"\"\n",
    "    compute the forward pass of the net\n",
    "    :param input: input data to the first hidden layer\n",
    "    :param layers: hidden layers\n",
    "    :return: a tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    # computes matrix multiply in forward pass\n",
    "    for layer in layers:\n",
    "        weights = layer[0]\n",
    "        activation_func = layer[1]\n",
    "        input = activation_func(tf.matmul(input,weights))\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimizer(name,learning_rate = 0.1):\n",
    "    \"\"\"\n",
    "    Select user specified optimizer\n",
    "    :param name: name of optimizer\n",
    "    :param learning_rate: optimizer's learning rate\n",
    "    :return: optimizer object\n",
    "    \"\"\"\n",
    "    \n",
    "    name = name.lower()\n",
    "    # list of optimizers    \n",
    "    optimizers = set([\"adam\",\"gd\",\"adagrad\",\"adadelta\"])\n",
    "    assert name in optimizers\n",
    "    return {\n",
    "        \"gd\" : tf.train.GradientDescentOptimizer(learning_rate=learning_rate),\n",
    "        \"adam\" : tf.train.AdamOptimizer(learning_rate=learning_rate),\n",
    "        \"adagrad\" : tf.train.AdagradOptimizer(learning_rate=learning_rate),\n",
    "        \"adadelta\": tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "    }.get(name)\n",
    "\n",
    "def select_activation_func(name):\n",
    "    \"\"\"\n",
    "    Selects user specified activation func\n",
    "    :param name: name of activation func\n",
    "    :return: activation func\n",
    "    \"\"\"\n",
    "    \n",
    "    name = name.lower()\n",
    "    # list of activation funcs\n",
    "    activations = set([\"sigmoid\",\"relu\",\"tanh\"])\n",
    "    assert name in activations\n",
    "    return {\n",
    "        \"sigmoid\" : tf.sigmoid,\n",
    "        \"relu\" : tf.nn.relu,\n",
    "        \"tanh\" : tf.tanh\n",
    "    }.get(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Train the model. In low level tensorflow, training the model (which is a contained in a Graph) occurs in a Session. Here I also plot the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,model_variables):\n",
    "    \"\"\"\n",
    "    train model and plot accuracy\n",
    "    :param model: graph object containing net\n",
    "    :param model_variables: list of tensors/ops such as optimizer, loss, etc. to run in session\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # list of accuracy for each batch\n",
    "    accuracy_points = []\n",
    "    \n",
    "    # start session\n",
    "    with tf.Session(graph=model) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        # training-- get batch until no batches left\n",
    "        while(True):\n",
    "            try:\n",
    "                predictions, l, _, acc = session.run(model_variables)\n",
    "                accuracy_points.append(acc)\n",
    "            except:                \n",
    "                break\n",
    "        \n",
    "        # plot data and end session\n",
    "        plt.plot(accuracy_points)\n",
    "        plt.show()\n",
    "        session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}